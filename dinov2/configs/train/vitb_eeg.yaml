MODEL:
  WEIGHTS: ''
ibot:
  separate_head: true
  mask_sample_probability: 0.5
  mask_ratio_min_max:
  - 0.1
  - 0.5
  mask_min_aspect: 0.15
train:
  batch_size_per_gpu: 3
  # dataset_path: ImageNet:split=TRAIN
  centering: sinkhorn_knopp
dataset:
  data_root: ./samples
  num_channels: 19
  num_patches_per_channel: 30
  patch_time_dim: 250  # sampling rate 250Hz -> 1s patches
crops:
  # local_crops_number: 8
  local_crop_size_channels: 10
  local_crop_size_patches: 15
augmentation:
  global_aug_probs: [1.0, 0.1] # Global crop-1 100% augmentation, Global crop-2 10% augmentation
  local_aug_prob: 0.5          # Local crops 50% augmentation
  scale_prob: 0.3              # Amplitude Scale
  scale_sigma: 0.2             # Amplitude Scale
  noise_prob: 0.3              # Gaussian Noise
  noise_std_range: [0.05, 0.1] # Gaussian Noise
  dropout_ch_prob: 0.1         # Channel Dropout
  dropout_max_channels: 3      # Channel Dropout
  dropout_as_noise_prob: 0.5   # Channel Dropout
  time_shift_prob: 0.3         # Time Shift
  max_time_shift_ratio: 0.05   # Time Shift
  phase_perturb_prob: 0.3      # Phase Perturbation
  phase_perturb_rad: 0.2       # Phase Perturbation

student:
  arch: vit_base
  pretrained_weights: ''
  # patch_size: 14
  # patch_time_dim: 250  # sampling rate 250Hz -> 1s patches
  drop_path_rate: 0.4
  num_register_tokens: 4
  ffn_layer: mlp # it is used in checkpoint from torch hub
  block_chunks: 0
teacher:
  momentum_teacher: 0.994
  warmup_teacher_temp_epochs: 60
optim:
  epochs: 200
  weight_decay_end: 0.2
  base_lr: 4.0e-04  # learning rate for a batch size of 1024
  warmup_epochs: 60
  layerwise_decay: 1.0

evaluation:
  eval_period_iterations: 1000